{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.utils.data\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import gc\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.nn import Sequential\n",
    "import os\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from sklearn.metrics import f1_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '.'\n",
    "train_path = base_path + '/train_data'\n",
    "train_medium_path = train_path + '/medium'\n",
    "\n",
    "val_path = base_path + '/validation_classification'\n",
    "val_medium_path = val_path + '/medium'\n",
    "\n",
    "test_path = base_path + '/test_classification'\n",
    "test_medium_path = test_path + '/medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyImageFolder(ImageFolder):\n",
    "    def _find_classes(self, dir):\n",
    "        \"\"\"\n",
    "        Finds the class folders in a dataset.\n",
    "\n",
    "        Args:\n",
    "            dir (string): Root directory path.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n",
    "\n",
    "        Ensures:\n",
    "            No class is a subdirectory of another.\n",
    "        \"\"\"\n",
    "        if sys.version_info >= (3, 5):\n",
    "            # Faster and available in Python 3.5 and above\n",
    "            classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
    "        else:\n",
    "            classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "        classes\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_image = transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.RandomCrop(64),\n",
    "        transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imagefolder = MyImageFolder(val_medium_path, transform = transform_image)\n",
    "image_val_dataloader = DataLoader(val_imagefolder,\n",
    "                                    batch_size = 32,\n",
    "                                    drop_last = False,\n",
    "                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c1a9bf5fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(val_imagefolder[3][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_imagefolder[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestImageFolder(DatasetFolder):\n",
    "    \n",
    "    def __init__(self, root, extensions=None, transform=None):\n",
    "        super(DatasetFolder, self).__init__(root, transform=transform)\n",
    "        \n",
    "        self.root = root\n",
    "        self.loader = default_loader\n",
    "        self.extensions = extensions\n",
    "        self.samples = list(os.walk(root))[0][2]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        file_name = self.samples[index]\n",
    "        sample = self.loader(os.path.join(self.root, file_name))\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_accuracy(model):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval().cuda()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for index, (val_features, val_labels) in enumerate(image_val_dataloader):\n",
    "            val_features = val_features.cuda()\n",
    "\n",
    "            outputs = model(val_features).view(val_labels.shape[0], -1)\n",
    "            predictions = torch.max(outputs.data, 1)[1]\n",
    "            y_pred += list(predictions.data.cpu().numpy())\n",
    "            y_true += list(val_labels.numpy())\n",
    "        \n",
    "    f1 = f1_score(y_true = y_true, y_pred = y_pred, average='weighted')\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_accuracy(model):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval().cuda()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for index, (val_features, val_labels) in enumerate(image_val_dataloader):\n",
    "            val_features = val_features.cuda()\n",
    "\n",
    "            outputs = model(val_features).view(val_labels.shape[0], -1)\n",
    "            predictions = torch.max(outputs.data, 1)[1]\n",
    "            y_pred += list(predictions.data.cpu().numpy())\n",
    "            y_true += list(val_labels.numpy())\n",
    "        \n",
    "    return sum(np.array(y_true) == np.array(y_pred))/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convolutional_layers = Sequential(\n",
    "            #first part-29\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 4, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "\n",
    "            #second part-14\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 2, stride = 2, padding = 2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            nn.Dropout2d(0.2)\n",
    "        )\n",
    "\n",
    "        self.output_layers = Sequential(\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(2048, 2300)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        conv_output = self.convolutional_layers(x)\n",
    "        \n",
    "        output = self.output_layers(conv_output.view(conv_output.shape[0], -1))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ReLU, Conv2d, MaxPool2d, BatchNorm1d, BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVGG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        inplace = True\n",
    "        \n",
    "        self.convolutional_layers = Sequential(\n",
    "            Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "\n",
    "        self.output_layers = Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(2048, 2300)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        conv_output = self.convolutional_layers(x)\n",
    "        \n",
    "        output = self.output_layers(conv_output.view(conv_output.shape[0], -1))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVGG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        inplace = True\n",
    "        \n",
    "        self.convolutional_layers = Sequential(\n",
    "            Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            ReLU(inplace),\n",
    "            MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "\n",
    "        self.output_layers = Sequential(\n",
    "            nn.Linear(32768, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(2048, 2300)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        conv_output = self.convolutional_layers(x)\n",
    "        \n",
    "        output = self.output_layers(conv_output.view(conv_output.shape[0], -1))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class MyCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convolutional_layers = Sequential(\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.output_layers = Sequential(\n",
    "            nn.Linear(3072, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(2048, 2300)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        conv_output = self.convolutional_layers(x)\n",
    "        output = self.output_layers(conv_output.view(conv_output.shape[0], -1))\n",
    "        \n",
    "        return output'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class MyVGG(nn.Module)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\1/.cache\\torch\\hub\\pytorch_vision_v0.5.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.5.0', 'vgg11', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\Anaconda3\\envs\\python3.5\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyVGG(\n",
       "  (convolutional_layers): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (output_layers): Sequential(\n",
       "    (0): Linear(in_features=32768, out_features=4096, bias=True)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (5): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=2048, out_features=2300, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyVGG()\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagefolder = MyImageFolder(train_medium_path, transform = transform_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [imagefolder.targets.count(target) for target in range(2300)]\n",
    "target_counts = np.array([counts[target] for target in imagefolder.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_weights = 1/target_counts\n",
    "weighted_sampler = WeightedRandomSampler(weights = target_weights,\n",
    "                                         replacement = True,\n",
    "                                         num_samples = len(target_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train_dataloader = DataLoader(imagefolder,\n",
    "                                    batch_size = 64,\n",
    "                                    drop_last = False,\n",
    "                                    shuffle = False,\n",
    "                                    sampler = weighted_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004347826086956522"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss: 7.701126388072968\n",
      "average loss: 7.347619277477264\n",
      "average loss: 7.086101522922516\n",
      "average loss: 6.856671692371369\n",
      "average loss: 6.6622455458641054\n",
      "average loss: 6.483898948192596\n",
      "average loss: 6.3314166231155395\n",
      "average loss: 6.179625605583191\n",
      "average loss: 6.033585300445557\n",
      "average loss: 5.898634771347046\n",
      "average loss: 5.752074809074402\n",
      "average loss: 5.627170861244202\n",
      "Epoch 1 Done.\n",
      "Validation Accuracy 0.11043478260869566\n",
      "average loss: 5.386026895523071\n",
      "average loss: 5.2705832796096805\n",
      "average loss: 5.138296898841858\n",
      "average loss: 5.014059167385101\n",
      "average loss: 4.911017042160034\n",
      "average loss: 4.797651696205139\n",
      "average loss: 4.688587040901184\n",
      "average loss: 4.576223440885544\n",
      "average loss: 4.497058034181594\n",
      "average loss: 4.391749188423157\n",
      "average loss: 4.2895171909332275\n",
      "average loss: 4.213729162216186\n",
      "Epoch 2 Done.\n",
      "Validation Accuracy 0.25369565217391304\n",
      "average loss: 4.051757622957229\n",
      "average loss: 3.9613748376369475\n",
      "average loss: 3.890374097824097\n",
      "average loss: 3.8171429622173307\n",
      "average loss: 3.7292621762752534\n",
      "average loss: 3.666837481737137\n",
      "average loss: 3.600328631401062\n",
      "average loss: 3.523104860544205\n",
      "average loss: 3.4540478894710542\n",
      "average loss: 3.3992357723712923\n",
      "average loss: 3.3166472582817077\n",
      "average loss: 3.247266697645187\n",
      "Epoch 3 Done.\n",
      "Validation Accuracy 0.32717391304347826\n",
      "average loss: 3.1527171797752382\n",
      "average loss: 3.0724456174373627\n",
      "average loss: 3.02568875002861\n",
      "average loss: 2.963585067510605\n",
      "average loss: 2.925177230119705\n",
      "average loss: 2.8681150509119036\n",
      "average loss: 2.801382282495499\n",
      "average loss: 2.747843225598335\n",
      "average loss: 2.7058240379095078\n",
      "average loss: 2.6520908043384552\n",
      "average loss: 2.599905882716179\n",
      "average loss: 2.5409666080474853\n",
      "Epoch 4 Done.\n",
      "Validation Accuracy 0.3869565217391304\n",
      "average loss: 2.4596312901973723\n",
      "average loss: 2.3969488589763643\n",
      "average loss: 2.3522868328094484\n",
      "average loss: 2.311547544836998\n",
      "average loss: 2.260378205180168\n",
      "average loss: 2.218801285147667\n",
      "average loss: 2.176737867832184\n",
      "average loss: 2.1386742322444916\n",
      "average loss: 2.102924156665802\n",
      "average loss: 2.0642263408899306\n",
      "average loss: 2.0116067037582397\n",
      "average loss: 1.9612478938102722\n",
      "Epoch 5 Done.\n",
      "Validation Accuracy 0.4256521739130435\n",
      "average loss: 1.8879836492538453\n",
      "average loss: 1.870123988389969\n",
      "average loss: 1.8154370412826537\n",
      "average loss: 1.7769823130369187\n",
      "average loss: 1.7663007330894471\n",
      "average loss: 1.702977303981781\n",
      "average loss: 1.6680751683712005\n",
      "average loss: 1.6407970749735832\n",
      "average loss: 1.6023557304143905\n",
      "average loss: 1.560382440686226\n",
      "average loss: 1.5406837623119354\n",
      "average loss: 1.4985547429919244\n",
      "Epoch 6 Done.\n",
      "Validation Accuracy 0.44521739130434784\n",
      "average loss: 1.4365629272460938\n",
      "average loss: 1.406272825062275\n",
      "average loss: 1.3706515449881553\n",
      "average loss: 1.3414742442965508\n",
      "average loss: 1.3277266676425934\n",
      "average loss: 1.2984682840108872\n",
      "average loss: 1.2525048582553864\n",
      "average loss: 1.2293452518582344\n",
      "average loss: 1.2013058006167412\n",
      "average loss: 1.18391607016325\n",
      "average loss: 1.1614442957043647\n",
      "average loss: 1.1236279618144036\n",
      "Epoch 7 Done.\n",
      "Validation Accuracy 0.45652173913043476\n",
      "average loss: 1.0886166797280312\n",
      "average loss: 1.0502994705438613\n",
      "average loss: 1.0262786329388618\n",
      "average loss: 1.0027660075426101\n",
      "average loss: 0.9838886812329293\n",
      "average loss: 0.9517704326510429\n",
      "average loss: 0.9339775312840939\n",
      "average loss: 0.8962252477407455\n",
      "average loss: 0.8769633605480194\n",
      "average loss: 0.8585613211393356\n",
      "average loss: 0.8378750813603402\n",
      "average loss: 0.8207312714159488\n",
      "Epoch 8 Done.\n",
      "Validation Accuracy 0.46869565217391307\n",
      "average loss: 0.7811107043325901\n",
      "average loss: 0.7592134759426117\n",
      "average loss: 0.7479097610414028\n",
      "average loss: 0.7267610377073288\n",
      "average loss: 0.7107737663388253\n",
      "average loss: 0.6859496626257896\n",
      "average loss: 0.6766266853511334\n",
      "average loss: 0.6590858721137047\n",
      "average loss: 0.639688190728426\n",
      "average loss: 0.6213987733721733\n",
      "average loss: 0.6112634989917278\n",
      "average loss: 0.5991982313096523\n",
      "Epoch 9 Done.\n",
      "Validation Accuracy 0.473695652173913\n",
      "average loss: 0.5617776444256306\n",
      "average loss: 0.5541078161001205\n",
      "average loss: 0.5294007991999388\n",
      "average loss: 0.5301767274737358\n",
      "average loss: 0.5129644469916821\n",
      "average loss: 0.49911176423728465\n",
      "average loss: 0.4852338607907295\n",
      "average loss: 0.47723482066392897\n",
      "average loss: 0.4626584985256195\n",
      "average loss: 0.4482247557491064\n",
      "average loss: 0.4401917282640934\n",
      "average loss: 0.43367534413933756\n",
      "Epoch 10 Done.\n",
      "Validation Accuracy 0.4678260869565217\n",
      "average loss: 0.4079775771051645\n",
      "average loss: 0.4081776865124703\n",
      "average loss: 0.38905928188562394\n",
      "average loss: 0.3843314589112997\n",
      "average loss: 0.3757664484381676\n",
      "average loss: 0.3528733994215727\n",
      "average loss: 0.35054721440374853\n",
      "average loss: 0.33872986514866354\n",
      "average loss: 0.33020171500742435\n",
      "average loss: 0.3292794833034277\n",
      "average loss: 0.31846621400117875\n",
      "average loss: 0.31421853964030744\n",
      "Epoch 11 Done.\n",
      "Validation Accuracy 0.47804347826086957\n",
      "average loss: 0.2931036557406187\n",
      "average loss: 0.2842293567061424\n",
      "average loss: 0.2813762686699629\n",
      "average loss: 0.2762838020324707\n",
      "average loss: 0.26150006520748137\n",
      "average loss: 0.25939607159793376\n",
      "average loss: 0.2576372005492449\n",
      "average loss: 0.24464185455441476\n",
      "average loss: 0.2404175797998905\n",
      "average loss: 0.23500175178050994\n",
      "average loss: 0.2291005294919014\n",
      "average loss: 0.22412910133600236\n",
      "Epoch 12 Done.\n",
      "Validation Accuracy 0.48130434782608694\n",
      "average loss: 0.21666262160241603\n",
      "average loss: 0.20842581301927565\n",
      "average loss: 0.2070107318907976\n",
      "average loss: 0.20106306675076485\n",
      "average loss: 0.1965950710773468\n",
      "average loss: 0.19327360670268537\n",
      "average loss: 0.18519263854622842\n",
      "average loss: 0.183955231025815\n",
      "average loss: 0.17822574631869792\n",
      "average loss: 0.17127368342876434\n",
      "average loss: 0.17061808232963085\n",
      "average loss: 0.16455161912739277\n",
      "Epoch 13 Done.\n",
      "Validation Accuracy 0.47978260869565215\n",
      "average loss: 0.155889458283782\n",
      "average loss: 0.15214671137928962\n",
      "average loss: 0.1499818895459175\n",
      "average loss: 0.1488199368417263\n",
      "average loss: 0.14176677724719047\n",
      "average loss: 0.14018602854013443\n",
      "average loss: 0.13636677296459676\n",
      "average loss: 0.1302777495831251\n",
      "average loss: 0.13275350849330425\n",
      "average loss: 0.12863267208635806\n",
      "average loss: 0.1291192952170968\n",
      "average loss: 0.12380081687867642\n",
      "Epoch 14 Done.\n",
      "Validation Accuracy 0.48630434782608695\n",
      "average loss: 0.11848617723584175\n",
      "average loss: 0.1129845139235258\n",
      "average loss: 0.11276699262857437\n",
      "average loss: 0.11015274015069008\n",
      "average loss: 0.11182811478525401\n",
      "average loss: 0.10705729395151138\n",
      "average loss: 0.10447328570485115\n",
      "average loss: 0.10456784535199404\n",
      "average loss: 0.1014471792280674\n",
      "average loss: 0.09863349927961826\n",
      "average loss: 0.09358915381133556\n",
      "average loss: 0.0931939703375101\n",
      "Epoch 15 Done.\n",
      "Validation Accuracy 0.4926086956521739\n",
      "average loss: 0.09054209735989571\n",
      "average loss: 0.08944721768796444\n",
      "average loss: 0.08648768088966607\n",
      "average loss: 0.08642820586264134\n",
      "average loss: 0.08362325444072485\n",
      "average loss: 0.08349193625152111\n",
      "average loss: 0.08179291012138128\n",
      "average loss: 0.08101143065094948\n",
      "average loss: 0.08068643648922444\n",
      "average loss: 0.07644547162950038\n",
      "average loss: 0.07599801959842443\n",
      "average loss: 0.0744495962113142\n",
      "Epoch 16 Done.\n",
      "Validation Accuracy 0.49543478260869567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method Image.__del__ of <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32 at 0x2C23064C278>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\1\\Anaconda3\\envs\\python3.5\\lib\\site-packages\\PIL\\Image.py\", line 629, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-bc0d480f7346>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mavg_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         '''        \n\u001b[0;32m     25\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#15 epoches to 47%\n",
    "for i in range(100):\n",
    "    model.train().cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.001, weight_decay = 0, momentum = 0.9)\n",
    "    \n",
    "    avg_loss = 0\n",
    "    '''    \n",
    "    train_pred = []\n",
    "    train_true = []\n",
    "    '''\n",
    "    for index, (features, labels) in enumerate(image_train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        '''\n",
    "        train_true += list(labels.numpy())\n",
    "        '''\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        output = model(features).view(labels.shape[0], -1)\n",
    "        loss = criterion(output, labels.long())\n",
    "        loss.backward()\n",
    "        avg_loss += loss.item()\n",
    "        '''        \n",
    "        predictions = torch.max(output.data, 1)[1]\n",
    "        train_pred += list(predictions.data.cpu().numpy())\n",
    "        '''\n",
    "        optimizer.step() \n",
    "        \n",
    "        if index%1000 == 0 and index != 0:\n",
    "            print(\"average loss:\", avg_loss/1000)\n",
    "            avg_loss = 0\n",
    "            '''            \n",
    "            print(\"f1_score:\",f1_score( y_true=train_true, y_pred=train_pred, average='weighted'))\n",
    "            train_true = []\n",
    "            train_pred = [] \n",
    "            '''\n",
    "    print(\"Epoch {0} Done.\".format(i+1))\n",
    "    print(\"Validation Accuracy\", val_accuracy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('vgg_trial.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification_submission(model, idx_to_class, test_path = test_medium_path):\n",
    "    '''\n",
    "    using customized dataset\n",
    "    '''\n",
    "    test_dataset = TestImageFolder(test_path, transform = transform_image)\n",
    "    test_dataloader = DataLoader(test_dataset, \n",
    "                             batch_size = 32,\n",
    "                             drop_last = False,\n",
    "                             shuffle = False)\n",
    "    \n",
    "    submission_indices = test_dataloader.dataset.samples\n",
    "    submission_prediction = []\n",
    "    for index, (img) in enumerate(test_dataloader):\n",
    "        model.eval().cuda()\n",
    "        img = img.cuda()\n",
    "\n",
    "        outputs = model(img).view(img.shape[0], -1)\n",
    "        predictions = torch.max(outputs.data, 1)[1]\n",
    "        submission_prediction += list(predictions.data.cpu().numpy())\n",
    "    \n",
    "    submission_prediction = [idx_to_class[i] for i in submission_prediction]\n",
    "    submission_df = pd.DataFrame({'Category': submission_prediction}, index = submission_indices)\n",
    "    submission_df.to_csv('submission.csv', index_label = 'Id')\n",
    "    print(\"Submission File Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4980434782608696"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission File Saved.\n"
     ]
    }
   ],
   "source": [
    "idx_to_class = {j:i for i, j in val_imagefolder.class_to_idx.items()}\n",
    "make_classification_submission(model, idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
