{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.nn import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.nn import Sequential\n",
    "import os\n",
    "from torchvision.datasets import DatasetFolder\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pickle\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my files\n",
    "from MyResNet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '.'\n",
    "train_path = basepath + '/train_data'\n",
    "train_medium_path = train_path + '/medium'\n",
    "\n",
    "val_path = basepath + '/validation_classification'\n",
    "val_medium_path = val_path + '/medium'\n",
    "\n",
    "test_path = basepath + '/test_classification'\n",
    "test_medium_path = test_path + '/medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.CenterCrop(28),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "        transforms.CenterCrop(28),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation using normal transform\n",
    "val_imagefolder = ImageFolder(val_medium_path, transform = val_transform)\n",
    "#use more transforms for train dataset to get robust \n",
    "train_imagefolder = ImageFolder(train_medium_path, transform = train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataloader = DataLoader(val_imagefolder,\n",
    "                                    batch_size = 32,\n",
    "                                    drop_last = False,\n",
    "                                    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_imagefolder,\n",
    "                                    #when use 32 bits, 128 batch size works fine\n",
    "                                    batch_size = 32,\n",
    "                                    drop_last = True,\n",
    "                                    shuffle = True,\n",
    "                                    num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestImageFolder(DatasetFolder):\n",
    "    \n",
    "    def __init__(self, root, extensions=None, transform=None):\n",
    "        super(DatasetFolder, self).__init__(root, transform=transform)\n",
    "        \n",
    "        self.root = root\n",
    "        self.loader = default_loader\n",
    "        self.extensions = extensions\n",
    "        self.samples = list(os.walk(root))[0][2]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        file_name = self.samples[index]\n",
    "        sample = self.loader(os.path.join(self.root, file_name))\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_acc(model, dataloader):\n",
    "    \n",
    "    model.eval().cuda()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for index, (features, labels) in enumerate(dataloader):\n",
    "            features = features.cuda()\n",
    "            #labels = labels.cuda()\n",
    "            batch_size = features.shape[0]\n",
    "\n",
    "            outputs = model.forward(features).view(batch_size, -1)\n",
    "            preds = torch.max(outputs.data, 1)[1]\n",
    "            Y_p += list(preds.data.cpu().numpy())\n",
    "            Y_t += list(labels.numpy())\n",
    "        \n",
    "    return sum(np.array(Y_p) == np.array(Y_t))/len(Y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_acc(model, dataloader):\n",
    "    \n",
    "    model.eval().cuda()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for index, (features, labels) in enumerate(dataloader):\n",
    "            features = features.cuda()\n",
    "            #labels = labels.cuda()\n",
    "            batch_size = features.shape[0]\n",
    "\n",
    "            outputs = model(features).view(batch_size, -1)\n",
    "            preds = torch.max(outputs.data, 1)[1]\n",
    "            Y_p += list(preds.data.cpu().numpy())\n",
    "            Y_t += list(labels.numpy())\n",
    "        \n",
    "    return sum(np.array(Y_p) == np.array(Y_t))/len(Y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_validation_acc(models, dataloader):\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for model in models:\n",
    "            model.eval().cuda()\n",
    "        \n",
    "        Y_p = []\n",
    "        Y_t = []\n",
    "        for index, (features, labels) in enumerate(dataloader):\n",
    "            \n",
    "            features = features.cuda()\n",
    "            #labels = labels.cuda()\n",
    "            batch_size = features.shape[0]\n",
    "\n",
    "            outputs = torch.zeros((batch_size, 2300))\n",
    "            for model in models:\n",
    "                outputs += model(features).view(batch_size, -1).cpu()\n",
    "            \n",
    "            preds = torch.max(outputs.data, 1)[1]\n",
    "            Y_p += list(preds.data.cpu().numpy())\n",
    "            Y_t += list(labels.numpy())\n",
    "            \n",
    "    return sum(np.array(y_true) == np.array(y_pred))/len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = MyResNet(BasicBlock, [1, 2, 3, 4])\n",
    "    #downsample less in the first few layers\n",
    "    # since I used mean value of several resnet, I trained five models.\n",
    "    '''\n",
    "    model = MyResNet(BasicBlock, [2, 2, 3, 2])\n",
    "    model = MyResNet(BasicBlock, [2, 3, 3, 2])\n",
    "    model = MyResNet(BasicBlock, [1, 3, 3, 2])\n",
    "    model = MyResNet(BasicBlock, [1, 2, 4, 1])\n",
    "    '''\n",
    "    n_epoches = 15\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                lr = 0.05,\n",
    "                                weight_decay = 5e-6,\n",
    "                                momentum = 0.9)\n",
    "    \n",
    "    train_dataloader = train_dataloader\n",
    "    validation_dataloader = validation_dataloader\n",
    "    check_iter = 500\n",
    "    #start epoch\n",
    "    for epoch in range(n_epoches):\n",
    "        print(\"Epoch {0} starts.\".format(epoch+1))\n",
    "        model = model.train().cuda()\n",
    "        temp_avg_loss = 0\n",
    "        last_avg_loss = 1e10\n",
    "        batch_size = train_dataloader.batch_size\n",
    "        \n",
    "        for index, (features, targets) in enumerate(train_dataloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #to cuda\n",
    "            features = features.cuda()\n",
    "            targets = targets.cuda()\n",
    "            \n",
    "            model.cuda()\n",
    "            outputs = model(features).view(batch_size, -1)\n",
    "            \n",
    "            loss = criterion(outputs, targets.long())\n",
    "            loss.backward()\n",
    "            #sum loss\n",
    "            temp_avg_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (index+1)%check_iter == 0:\n",
    "                temp_avg_loss /= check_iter\n",
    "                print(temp_avg_loss)\n",
    "                if temp_avg_loss >= last_avg_loss:\n",
    "                    # if the average loss between two check points increase, decay the learning rate\n",
    "                    for param in optimizer.param_groups:\n",
    "                        param['lr'] /= 2\n",
    "                    print(\"Decay learning rate to {0}.\".format(optimizer.param_groups[0]['lr']))\n",
    "        print(\"Epoch {0} ends.\".format(epoch+1))\n",
    "        #validate the result\n",
    "        print(validation_acc(model, validation_dataloader))\n",
    "        \n",
    "    #change file name when store different models\n",
    "    torch.save(model, \"SingleModel1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "#file_names = [\"SingleModel1.pt\", \"SingleModel2.pt\", \"SingleModel3.pt\", \"SingleModel4.pt\", \"SingleModel5.pt\"]\n",
    "file_names = [\"SingleModel1.pt\"]\n",
    "              \n",
    "for file_name in file_names:\n",
    "    model = torch.load(file_name)\n",
    "    model_list.append(model)\n",
    "\n",
    "ensemble_validation_accuracy = ensemble_validation_acc(model_list, validation_dataloader)\n",
    "print(\"Ensemble validation accuracy is\", ensemble_validation_accuracy)\n",
    "\n",
    "# This generates the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ensemble_classification_submission(model_list, idx2class):\n",
    "    \n",
    "    # TestImageFolder is defined in previous section\n",
    "    batch_size = 64\n",
    "    test_datafolder = TestImageFolder(test_medium_path, transform = val_transform)\n",
    "    test_dataloader = DataLoader(test_datafolder, \n",
    "                             batch_size = batch_size,\n",
    "                             drop_last = False,\n",
    "                             shuffle = False)\n",
    "    \n",
    "    sub_index = test_dataloader.dataset.samples\n",
    "    sub_preds = []\n",
    "    \n",
    "    for model in model_list:\n",
    "        model.eval().cuda()\n",
    "        \n",
    "    for index, (features) in enumerate(test_dataloader):\n",
    "        \n",
    "        features = features.cuda()\n",
    "        \n",
    "        outputs = torch.zeros((features.shape[0], 2300))\n",
    "        for model in model_list:\n",
    "            outputs += model.forward(features).view(features.shape[0], -1).cpu()\n",
    "            \n",
    "        preds = torch.max(outputs.data, 1)[1]\n",
    "        sub_preds += list(preds.data.cpu().numpy())\n",
    "    \n",
    "    sub_preds = [idx2class[i] for i in sub_preds]\n",
    "    submission_df = pd.DataFrame({'Category': sub_preds}, index = sub_index)\n",
    "    submission_df.to_csv('submission.csv', index_label = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map the prediction to real class\n",
    "idx2class = {idx:cls for cls, idx in val_imagefolder.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ensemble_classification_submission(model_list, idx2class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(img_path, transforms, base_path):\n",
    "    img = Image.open(base_path + '/' + img_path)\n",
    "    img = val_transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationImageDataset(Dataset):\n",
    "    def __init__(self, veri_file, transforms = val_transform, test_mode = False):\n",
    "        \n",
    "        self.veri_file = veri_file\n",
    "        self.transforms = transforms\n",
    "        self.img1 = [i.split()[0] for i in open(veri_file, 'r').readlines()]\n",
    "        self.img2 = [i.split()[1] for i in open(veri_file, 'r').readlines()]\n",
    "        self.test_mode = test_mode\n",
    "        if test_mode == True:\n",
    "            self.labels = [-1]*len(open(veri_file, 'r').readlines())\n",
    "        else:\n",
    "            self.labels = [int(i.split()[2]) for i in open(veri_file, 'r').readlines()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.test_mode == False:\n",
    "            return parse_data(self.img1[index], self.transforms, val_veri_path), parse_data(self.img2[index], self.transforms, val_veri_path), torch.Tensor([self.labels[index]])\n",
    "        else:\n",
    "            return parse_data(self.img1[index], self.transforms, test_veri_path), parse_data(self.img2[index], self.transforms, test_veri_path), torch.Tensor([self.labels[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_dataset = VerificationImageDataset(\"validation_trials_verification.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_dataloader = DataLoader(verification_dataset,\n",
    "                            batch_size = 128,\n",
    "                            drop_last = False,\n",
    "                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "def make_veri_prediction(model):\n",
    "    #using cosine similarity, no fine-tuning\n",
    "    model.eval()\n",
    "    td = VerificationImageDataset(\"test_trials_verification_student.txt\", test_mode=True)\n",
    "    test_dataloader = DataLoader(td,\n",
    "                            batch_size = 100,\n",
    "                            drop_last = False,\n",
    "                            shuffle = False)\n",
    "    simi = []\n",
    "    \n",
    "    for i, (img1, img2, labels) in enumerate(test_dataloader):\n",
    "        output_img1 = model(img1.cuda())\n",
    "        output_img2 = model(img2.cuda())\n",
    "\n",
    "        simi.append(cosine_similarity(output_img1, output_img2).detach().cpu().numpy())\n",
    "        del output_img1\n",
    "        del output_img2\n",
    "    \n",
    "    total_simi = np.concatenate(simi)\n",
    "    \n",
    "    output = pd.DataFrame({'trial':open(\"test_trials_verification_student.txt\").readlines(), 'score':total_simi})\n",
    "    output.to_csv(\"verification_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"SingleModel1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = ''\n",
    "val_veri_path = base_path + 'validation_verification'\n",
    "val_veri_txt_path = base_path + 'validation_trials_verification.txt'\n",
    "\n",
    "test_veri_path = base_path + 'test_verification/test_verification'\n",
    "test_veri_txt_path = base_path + 'test_trials_verification_student.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_veri_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
